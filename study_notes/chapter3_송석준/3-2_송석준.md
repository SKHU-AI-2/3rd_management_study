# 3.2 Multiple Linear Regression

단순한 선형 회귀는 단일 변수만 있을 때는 효과적인 도구였지만 하나보다 더 많은 변수들이 있을 때는 조금 다른 방법을 사용해야 한다.
한가지 방법은 변수마다 각각 단순한 선형 회귀를 사용해 각기 response에 어떤 관계를 가지는지 알아내는 것이다. 하지만 이 접근 방식은 서로 분리된 회귀 방정식을 지니고 있기 때문에 하나의 예측을 만들어내는 방법이 불분명하다. 게다가 각각의 선형 방정식이 다른 변수들은 완전히 무시하고 있다.

대신에 단순한 선형 회귀를 확장해서 mutiple predictors로 계산할 수 있도록 하는 것이 합리적이다. 각각의 변수에 해당하는 slope coefficient를 부여하는 것으로 가능하다.
![](https://velog.velcdn.com/images/suwdle/post/1b47879f-9c9f-4931-933f-698817d1d5dc/image.png)
### 3.2.1 Estimating the Regression Coefficients
![](https://velog.velcdn.com/images/suwdle/post/bfadea58-36f1-41ba-8de8-3b04cbede98a/image.png)
![](https://velog.velcdn.com/images/suwdle/post/8d3b802f-ae26-4312-a273-883b58ac77fe/image.png)

한마디로 단일 선형 회귀의 일반화이다.
이론적으로는 덧붙일 내용이 없지만, 다중 회귀 분석을 수행할 때의 예시가 좋아 정리해둔다.
만약 상관 행렬이 다음과 같을 때, 신문 광고량이 높을수록 라디오 광고량도 높은 경향을 보인다. 신문 광고량과 판매량과의 상관관계가 크지 않더라도, 신문 광고량이 라디오 광고량과 높은 양의 상관관계를 지니고 있으므로 신문 광고량이 높을수록 판매량이 높게 측정이 될 것이라는 것을 알 수 있다. 즉, 신문 광고량과 판매량의 관계는 라디오 광고량과 판매량의 관계에서 온 일종의 credit인 것이다.
### 3.2.2 Some Important Questions
다중 회귀를 수행할 때 다음과 같은 중요한 질문들에 관심을 가져야 한다.
1. 변수 X1, X2, X3...들 중 하나라도 정답을 예측하는 것에 유용한 것이 있는가?
2. 모든 변수가 Y를 설명하는 것에 도움이 되는가, 아니라면 유용한 변수들의 종속 변수일 뿐인가?
3. 얼마나 모델이 데이터에 잘 fit하는가?
4. 예측할 y 값은 무엇이고, 예측이 얼마나 정확한지 어떻게 평가하는가?

### One: Is there a Relationship Between the Response and Predictors?
단순 선형 회귀 문제에서 봤던 것처럼 먼저 귀무가설을 정하고 시작하자.
![](https://velog.velcdn.com/images/suwdle/post/502886e7-3b07-42dd-bea6-5a6fa06441ab/image.png)
대립 가설은 자연스럽게
![](https://velog.velcdn.com/images/suwdle/post/0e247079-579a-4b6e-9bbd-f98b55d71e1b/image.png)

이 가설 검증은 F-statics를 통해 수행한다.
![](https://velog.velcdn.com/images/suwdle/post/18b439c4-f13d-48a8-842b-e2be77ddacfe/image.png)
만약 선형 모델 가정이 맞다면, RSS를 포함한 분모항은
![](https://velog.velcdn.com/images/suwdle/post/1914c457-0e99-472f-a16d-2b4daa2751ca/image.png)
이 항등식을 만족한다. 이 식을 풀어보자면, 잔차 제곱 합의 평균(n-p-1은 통계적 자유도의 측면에서 설정한 값이다)이 입실론 값의 분산과 같다는 것이다. 즉 회귀 모델로 설명한 뒤 남은 y의 variability가 입실론의 분산이라는 것이니, 가장 이상적인 모델에 대한 값일 것이다. 책에 자세히 서술되어있지 않으나, 설명하고 싶은 바는 분모의 최소값이 입실론의 분산이라는 것인 듯하다.
그 가정만 참으로 성립되어도 F-statics를 설명하는데 충분하다.
그리고 귀무가설이 참이라면,
![](https://velog.velcdn.com/images/suwdle/post/ce1f9b3b-4c09-4ca4-8a73-a7ec84235d3e/image.png)
을 만족한다. TSS-RSS의 의미는 [회귀계수](https://velog.io/@suwdle/ISL-Linear-Regression)를 알아볼 때도 그 의미를 살펴본 적이 있는데, y로만 측정한 y의 가변성에서 회귀 모델 적용 후 가변성을 뺀 것이다. 즉, 회귀 모델이 설명하는 y의 가변성으로서 이 값이 클수록 모델이 더 잘 설명하고 있다는 것이다.(y만으로 측정한 가변성 - 모델로 측정하지 못한 가변성)

귀무가설이 참일 때 분자항이 입실론의 분산과 같다는 건 회귀 모델이 아무 것도 설명하지 못한다는 것이다.
그러므로 변수와 정답 사이 아무런 관계가 없다면 F-stastics는 1에 가까워질 것이고 대립가설이 참이라면 분자 항이 입실론의 분산보다 커져 1보다 더 커질 것이다.
하지만 F-stastics가 어느 정도 커야 귀무가설을 기각하고 변수와 정답 사이의 관계가 있다고 결론을 내릴 수 있을까? 의외로 그 답은 n과 p 값에 달려있다. n이 클 때, 즉 데이터의 수가 많을 때 1보다 조금 큰 F-stastics는 귀무가설을 반박하기 위한 증거가 될 수 있지만 n이 작을 때는 귀무가설을 기각하기 위해 더 큰 F-stastics를 필요로 한다. n이 작을 때 우연히 높게 측정될 가능성이 높을 것이다.

그런데 각 변수에 대한 t-stastics와 그에 따른 p-value를 연산하고 사용할 수도 있을 텐데, 왜 굳이 F-statstics를 사용하는 것일까? 만약 변수가 많은 경우에 변수들과 정답 사이 아무런 관계가 없더라도 낮은 p-value가 산출될 가능성이 크다.
그러나 F-stastics는 변수의 수로 조절되기 때문에 이런 문제를 해결할 수 있다.
하지만 F-stastics는 당연히 p가 n보다 클 때를 대응하지 못하는데, 이런 경우에는 다중회귀모델을 least squares를 적용해서 학습시키지도 못할 것이다.